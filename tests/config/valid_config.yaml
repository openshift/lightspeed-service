---
llm_providers:
  - name: p1
    type: bam
    url: "https://url1"
    credentials_path: tests/config/secret/apitoken
    models:
      - name: m1
        url: "https://murl1"
        credentials_path: tests/config/secret/apitoken
        context_window_size: 450
        parameters:
          max_tokens_for_response: 100
      - name: m2
        url: "https://murl2"
  - name: p2
    type: openai
    url: "https://url2"
    models:
      - name: m1
        url: "https://murl1"
      - name: m2
        url: "https://murl2"
ols_config:
  max_workers: 1
  reference_content:
    indexes:
      - product_docs_index_path: "tests/config"
        product_docs_index_id: product
  conversation_cache:
    type: memory
    memory:
      max_entries: 1000
  logging_config:
    logging_level: INFO
  default_provider: p1
  default_model: m1
  user_data_collection:
    transcripts_disabled: true
  certificate_directory: "/foo/bar/baz/xyzzy"
  system_prompt_path: "tests/config/system_prompt.txt"
mcp_servers:
  - name: foo
    url: http://localhost:8080
  - name: bar
    url: http://127.0.0.1:8081
    authorization_headers:
      X-API-Key: /path/to/secret
dev_config:
  disable_auth: true
  disable_tls: true
